{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab 2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTTjqafY58_7"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import urllib.request as url\n",
        "import itertools\n",
        "import re"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lum3uO-D6Sso"
      },
      "source": [
        "bakery5 = pd.read_csv(\"http://users.csc.calpoly.edu/~dekhtyar/466-Fall2021/data/BAKERY/5000/5000-out2.csv\", names=np.arange(0,50), index_col=0)\n",
        "bakery20 = pd.read_csv(\"http://users.csc.calpoly.edu/~dekhtyar/466-Fall2021/data/BAKERY/20000/20000-out2.csv\", names=np.arange(0,50), index_col=0)\n",
        "bakery75 = pd.read_csv(\"http://users.csc.calpoly.edu/~dekhtyar/466-Fall2021/data/BAKERY/75000/75000-out2.csv\", names=np.arange(0,50), index_col=0)\n",
        "\n",
        "food_labels = pd.read_csv(\"http://users.csc.calpoly.edu/~dekhtyar/466-Fall2021/data/BAKERY/goods.csv\")\n",
        "authors_labels = pd.read_csv(\"http://users.csc.calpoly.edu/~dekhtyar/466-Fall2021/data/BINGO/authorlist.psv\", delimiter=\"|\", names=[\"Id\",\"Authors\"])\n",
        "\n",
        "authors_dict = {}\n",
        "max = 0\n",
        "authors_file = url.urlopen(\"http://users.csc.calpoly.edu/~dekhtyar/466-Fall2021/data/BINGO/bingoBaskets.csv\")\n",
        "for line in authors_file:\n",
        "  data = line.decode(\"utf-8\").split(\",\", 1)\n",
        "  data[0] = int(data[0])\n",
        "  data[1] = [int(x.strip()) for x in data[1].split(\", \")]\n",
        "  for book in data[1]:\n",
        "    if book > max:\n",
        "      max = book\n",
        "  authors_dict[data[0]] = data[1]\n",
        "\n",
        "authors_list = np.zeros((len(authors_dict), max))\n",
        "for key in authors_dict.keys():\n",
        "  for book in authors_dict[key]:\n",
        "    authors_list[key][book - 1] = 1\n",
        "\n",
        "authors = pd.DataFrame(authors_list)\n",
        "authors.columns = np.arange(1, len(authors_list[0]) + 1)\n",
        "authors = authors.drop(1, axis=1)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Qt6eD1RDcbM"
      },
      "source": [
        "def update_skyline(skyline, combo, k):\n",
        "    for subset in combo[1]:\n",
        "        if subset in skyline[k-1]:\n",
        "            skyline[k-1].discard(subset)\n",
        "    if k not in skyline:\n",
        "        skyline[k] = set()\n",
        "    skyline[k].add(combo[0])\n",
        "\n",
        "def get_sets(s, n):\n",
        "    return [tuple(item) for item in itertools.combinations(s, n)]\n",
        "\n",
        "def candidate_gen(items, k, rules=False):\n",
        "    combos = []\n",
        "    seen = set()\n",
        "    for i in range(len(items)):\n",
        "        for j in range(i + 1, len(items)):\n",
        "            item = list(set.union(set(items[i]), set(items[j])))\n",
        "            item.sort()\n",
        "            item = tuple(item)\n",
        "            if len(item) == k:\n",
        "                add = True\n",
        "                subsets = get_sets(item, k-1)\n",
        "                for subset in subsets:\n",
        "                    if subset not in items:\n",
        "                        add = False\n",
        "                        break\n",
        "                if add and item not in seen:\n",
        "                    if rules:\n",
        "                        combos.append(item)\n",
        "                    else:\n",
        "                        combos.append((item, subsets))\n",
        "                    seen.add(item)\n",
        "    return combos\n",
        "\n",
        "def apriori(dataset, items, min_r_support):\n",
        "    n = dataset.shape[0]\n",
        "    k = 1\n",
        "    items.sort()\n",
        "\n",
        "    supports = {}\n",
        "    skyline = {k: set()}\n",
        "    last = []\n",
        "    for item in items:\n",
        "        if dataset[item].sum() / n >= min_r_support:\n",
        "            skyline[1].add((item, ))\n",
        "            supports[item] = dataset[item].sum() / n\n",
        "            last.append((item, ))\n",
        "\n",
        "    while k <= len(items):\n",
        "        k += 1\n",
        "        combos = candidate_gen(last, k)\n",
        "        last = []\n",
        "        for combo in combos:\n",
        "            total = None\n",
        "            for item in combo[0]:\n",
        "                if total is None:\n",
        "                    total = dataset[item].copy()\n",
        "                else:\n",
        "                    total *= dataset[item].copy()\n",
        "            if total.sum() / n >= min_r_support:\n",
        "                update_skyline(skyline, combo, k)\n",
        "                supports[combo[0]] = total.sum() / n\n",
        "                last.append(combo[0])\n",
        "        if len(last) == 0:\n",
        "            break\n",
        "\n",
        "    return skyline, supports"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5EOUHrPy7r3"
      },
      "source": [
        "class GenRules():\n",
        "    def __init__(self, table, freq_sets, min_conf):\n",
        "        self.table = table.copy()\n",
        "        self.freq_sets = freq_sets\n",
        "        self.min_conf = min_conf\n",
        "\n",
        "    def get_total(self, freq_set):\n",
        "        total = None\n",
        "        for item in freq_set:\n",
        "            if total is None:\n",
        "                total = self.table[item].copy()\n",
        "            else:\n",
        "                total *= self.table[item].copy()\n",
        "        return total\n",
        "\n",
        "    def confidence(self, item_set, subset):\n",
        "        item_set_total = self.get_total(item_set)\n",
        "        subset_total = self.get_total(subset)\n",
        "        return item_set_total.sum() / subset_total.sum()\n",
        "\n",
        "    def ap_gen_rules(self, item_set, rules, size):\n",
        "        new_rules = []\n",
        "        if len(item_set) > size and len(rules) > 0:\n",
        "            candidates = candidate_gen(rules, size, True)\n",
        "            new_candidates = []\n",
        "            for candidate in candidates:\n",
        "                subset = tuple([i for i in item_set if i not in candidate])\n",
        "                if self.confidence(item_set, subset) >= self.min_conf:\n",
        "                    new_rules.append(candidate)\n",
        "                    new_candidates.append(candidate)\n",
        "            new_rules += self.ap_gen_rules(item_set, new_candidates, size + 1)\n",
        "        return new_rules\n",
        "\n",
        "    def gen_rules(self):\n",
        "        all_rules = {}\n",
        "        for freq_set in self.freq_sets:\n",
        "            if len(freq_set) > 1:\n",
        "                rules = []\n",
        "                for item in freq_set:\n",
        "                    subset = tuple([i for i in freq_set if i != item])\n",
        "                    if self.confidence(freq_set, subset) >= self.min_conf:\n",
        "                        rules.append((item, ))\n",
        "                rules += self.ap_gen_rules(freq_set, rules, 2)\n",
        "                all_rules[freq_set] = rules\n",
        "        return self.skyline(all_rules)\n",
        "\n",
        "    def skyline(self, rules):\n",
        "        new_rules = {}\n",
        "        for key in rules.keys():\n",
        "            rule_list = rules[key]\n",
        "            if len(rule_list) == 0:\n",
        "                continue\n",
        "            length = len(rule_list[-1])\n",
        "            add_list = set()\n",
        "            library = {rule: True for rule in rule_list}\n",
        "            for rule in rule_list[::-1]:\n",
        "                for rule_2 in rule_list:\n",
        "                    if rule_2 == rule:\n",
        "                        continue\n",
        "                    add = False\n",
        "                    for val in rule_2:\n",
        "                        if val not in rule:\n",
        "                            add = True\n",
        "                    if add:\n",
        "                        add_list.add(rule_2)\n",
        "                    else:\n",
        "                        library[rule_2] = False\n",
        "            for rule in library.keys():\n",
        "                if not library[rule]:\n",
        "                    add_list.remove(rule)\n",
        "            if len(add_list) > 0:\n",
        "              new_rules[key] = list(add_list)\n",
        "        return new_rules"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vn5GuJ8knk6A"
      },
      "source": [
        "def get_confidence(table, main_set, subset):\n",
        "    def get_union(table, mset):\n",
        "        total = None\n",
        "        for item in mset:\n",
        "            if total is None:\n",
        "                total = table[item].copy()\n",
        "            else:\n",
        "                total *= table[item].copy()\n",
        "        return total\n",
        "    main_set_total = get_union(table.copy(), main_set)\n",
        "    subset_total = get_union(table.copy(), tuple([i for i in main_set if i not in subset]))\n",
        "    return main_set_total.sum() / subset_total.sum()"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMk4_119cIm4"
      },
      "source": [
        "def make_output(data, ap, support, labels, columns, minConf, authors=False):\n",
        "    for key in ap.keys():\n",
        "        for i in ap[key]:\n",
        "            t = GenRules(data, [i], minConf).gen_rules()\n",
        "            seen = set()\n",
        "            for items in t.keys():\n",
        "                intersect = []\n",
        "                for subset in t[items]:\n",
        "                    if isinstance(intersect, list) and len(t[items]) > 1:\n",
        "                        intersect = set(subset)\n",
        "                    else:\n",
        "                        intersect = intersect.intersection(set(subset))\n",
        "\n",
        "                items_copy = set(items)\n",
        "                for inter in intersect:\n",
        "                    items_copy.remove(inter)\n",
        "\n",
        "                for item in items_copy:\n",
        "                    string = []\n",
        "                    vals = labels[labels[\"Id\"] == item][columns].values.tolist()\n",
        "                    for val in vals:\n",
        "                        new_string = \" \".join(val)\n",
        "                        string.append(re.sub(r\"[^\\w\\s]\", \"\", new_string))\n",
        "\n",
        "                    new_items = []\n",
        "                    for item2 in items:\n",
        "                        if item2 != item:\n",
        "                            vals = labels[labels[\"Id\"] == item2][columns].values.tolist()\n",
        "                            for val in vals:\n",
        "                                new_string = \" \".join(val)\n",
        "                                new_items.append(re.sub(r\"[^\\w\\s]\", \"\", new_string))\n",
        "\n",
        "                    conf = get_confidence(data, items, [item])\n",
        "                    if conf > minConf:\n",
        "                        if not authors:\n",
        "                            print(\"{:>80}  {:>10}  {:<30} Support={:>4.2f}   Confidence={:>4.2f}\".format(\", \".join(new_items), \"------->\", \", \".join(string), support[items]*100, conf * 100))\n",
        "                        else:\n",
        "                            print(\"{:>40}  {:>10}  {:<30} Support={:>4.2f}   Confidence={:>4.2f}\".format(re.sub(r\"\\s\\s\", \" & \", new_items[0]), \"------->\", re.sub(r\"\\s\\s\", \" & \", string[0]), support[items]*100, conf * 100))"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-NAmdkEilmD"
      },
      "source": [
        "ap_auth, support_auth = apriori(authors, authors.columns.tolist(), 0.1)\n",
        "ap_bake, support_bake = apriori(bakery20, bakery5.columns.tolist(), 0.02)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6OJ_A5eQb_G9",
        "outputId": "3d815494-74eb-476a-9332-57a8b96bdfd2"
      },
      "source": [
        "make_output(authors, ap_auth, support_auth, authors_labels, [\"Authors\"], .35, authors=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                       Sanderson Brandon    ------->   Bancroft Josiah                         Support=20.58   Confidence=49.02\n",
            "                         Bancroft Josiah    ------->   Sanderson Brandon                       Support=20.58   Confidence=49.50\n",
            "                           Lawrence Mark    ------->   Rowe Andrew                             Support=11.52   Confidence=37.33\n",
            "                             Rowe Andrew    ------->   Lawrence Mark                           Support=11.52   Confidence=47.46\n",
            "                             Gaiman Neil    ------->   Pratchett Terry                         Support=11.93   Confidence=44.62\n",
            "                         Pratchett Terry    ------->   Gaiman Neil                             Support=11.93   Confidence=42.65\n",
            "                           Lawrence Mark    ------->   Sanderson Brandon                       Support=16.05   Confidence=52.00\n",
            "                       Sanderson Brandon    ------->   Lawrence Mark                           Support=16.05   Confidence=38.24\n",
            "                       Sanderson Brandon    ------->   Novik Naomi                             Support=14.81   Confidence=35.29\n",
            "                             Novik Naomi    ------->   Sanderson Brandon                       Support=14.81   Confidence=56.25\n",
            "                             Gaiman Neil    ------->   Sanderson Brandon                       Support=15.23   Confidence=56.92\n",
            "                       Sanderson Brandon    ------->   Gaiman Neil                             Support=15.23   Confidence=36.27\n",
            "                       Sanderson Brandon    ------->   Jemisin N K                             Support=16.87   Confidence=40.20\n",
            "                             Jemisin N K    ------->   Sanderson Brandon                       Support=16.87   Confidence=46.59\n",
            "                           Lawrence Mark    ------->   Gaiman Neil                             Support=11.93   Confidence=38.67\n",
            "                             Gaiman Neil    ------->   Lawrence Mark                           Support=11.93   Confidence=44.62\n",
            "                           Lawrence Mark    ------->   Bancroft Josiah                         Support=17.28   Confidence=56.00\n",
            "                         Bancroft Josiah    ------->   Lawrence Mark                           Support=17.28   Confidence=41.58\n",
            "                           Lawrence Mark    ------->   Eames Nicholas                          Support=11.52   Confidence=37.33\n",
            "                          Eames Nicholas    ------->   Lawrence Mark                           Support=11.52   Confidence=43.75\n",
            "                           Brennan Marie    ------->   Jemisin N K                             Support=13.58   Confidence=49.25\n",
            "                             Jemisin N K    ------->   Brennan Marie                           Support=13.58   Confidence=37.50\n",
            "                           Lawrence Mark    ------->   VanderMeer Jeff                         Support=11.52   Confidence=37.33\n",
            "                         VanderMeer Jeff    ------->   Lawrence Mark                           Support=11.52   Confidence=49.12\n",
            "                         Pratchett Terry    ------->   Bancroft Josiah                         Support=16.46   Confidence=58.82\n",
            "                         Bancroft Josiah    ------->   Pratchett Terry                         Support=16.46   Confidence=39.60\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QZc1RhZpAXAc",
        "outputId": "9adb38cc-38e7-4fb0-9b41-ff8434dc248e"
      },
      "source": [
        "make_output(bakery5, ap_bake, support_bake, food_labels, [\"Flavor\",\"Food\"], .84)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                   Apricot Croissant, Hot Coffee    ------->  Blueberry Tart                 Support=3.26   Confidence=94.25\n",
            "                                                      Blueberry Tart, Hot Coffee    ------->  Apricot Croissant              Support=3.26   Confidence=93.71\n",
            "                                                         Opera Cake, Cherry Tart    ------->  Apricot Danish                 Support=4.10   Confidence=93.58\n",
            "                                                      Opera Cake, Apricot Danish    ------->  Cherry Tart                    Support=4.10   Confidence=94.44\n",
            "                                                   Casino Cake, Chocolate Coffee    ------->  Chocolate Cake                 Support=3.39   Confidence=90.17\n",
            "                                                     Chocolate Cake, Casino Cake    ------->  Chocolate Coffee               Support=3.39   Confidence=91.23\n",
            "                                                  Coffee Eclair, Single Espresso    ------->  Blackberry Tart                Support=2.70   Confidence=96.62\n",
            "                                                Blackberry Tart, Single Espresso    ------->  Coffee Eclair                  Support=2.70   Confidence=91.08\n",
            "                                              Walnut Cookie, Vanilla Frappuccino    ------->  Chocolate Tart                 Support=2.83   Confidence=89.26\n",
            "                                                   Chocolate Tart, Walnut Cookie    ------->  Vanilla Frappuccino            Support=2.83   Confidence=93.01\n",
            "                                         Coffee Eclair, Almond Twist, Hot Coffee    ------->  Apple Pie                      Support=2.81   Confidence=100.00\n",
            "                                            Coffee Eclair, Apple Pie, Hot Coffee    ------->  Almond Twist                   Support=2.81   Confidence=100.00\n",
            "                                             Apple Pie, Almond Twist, Hot Coffee    ------->  Coffee Eclair                  Support=2.81   Confidence=100.00\n",
            "                                      Apple Croissant, Apple Danish, Cherry Soda    ------->  Apple Tart                     Support=2.10   Confidence=99.13\n",
            "                                        Apple Tart, Apple Croissant, Cherry Soda    ------->  Apple Danish                   Support=2.10   Confidence=99.13\n",
            "                                           Apple Tart, Apple Danish, Cherry Soda    ------->  Apple Croissant                Support=2.10   Confidence=100.00\n",
            "                   Raspberry Cookie, Lemon Cookie, Raspberry Lemonade, Green Tea    ------->  Lemon Lemonade                 Support=2.04   Confidence=100.00\n",
            "                       Raspberry Cookie, Lemon Cookie, Lemon Lemonade, Green Tea    ------->  Raspberry Lemonade             Support=2.04   Confidence=100.00\n",
            "                     Lemon Cookie, Lemon Lemonade, Raspberry Lemonade, Green Tea    ------->  Raspberry Cookie               Support=2.04   Confidence=100.00\n",
            "                 Raspberry Cookie, Lemon Lemonade, Raspberry Lemonade, Green Tea    ------->  Lemon Cookie                   Support=2.04   Confidence=100.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j7q2qsMEAB0X",
        "outputId": "8287198f-10d6-483d-bfc3-071fcbb37feb"
      },
      "source": [
        "def create_item_sets(ap, support, labels):\n",
        "  for key in ap.keys():\n",
        "    for item1 in ap[key]:\n",
        "      string = []\n",
        "      if len(item1) > 1:\n",
        "        for item2 in item1:\n",
        "          string.append(str(labels[labels[\"Id\"] == item2][\"Authors\"].values).strip(\"[]\").strip(\"'\").replace(\",\",\"\"))\n",
        "        print(\", \".join(string), \"[Support=\" + str(round(support[item1],2)) + \"]\")\n",
        "\n",
        "create_item_sets(ap_auth, support_auth, authors_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Bancroft Josiah,  Sanderson Brandon [Support=0.21]\n",
            " Bancroft Josiah,  Chambers Becky [Support=0.11]\n",
            " Bancroft Josiah,  Eames Nicholas [Support=0.14]\n",
            " Bancroft Josiah,  Mieville China [Support=0.12]\n",
            " Addison Katherine / Monette Sarah,  Lawrence Mark [Support=0.11]\n",
            " Bancroft Josiah,  Jemisin N. K. [Support=0.14]\n",
            " Pratchett Terry,  Sanderson Brandon [Support=0.14]\n",
            " Lawrence Mark,  Rowe Andrew [Support=0.12]\n",
            " Gaiman Neil,  Pratchett Terry [Support=0.12]\n",
            " King Stephen,  Sanderson Brandon [Support=0.1]\n",
            " Lawrence Mark,  Sanderson Brandon [Support=0.16]\n",
            " Hobb Robin / Lindholm Megan,  Sanderson Brandon [Support=0.13]\n",
            " Novik Naomi,  Sanderson Brandon [Support=0.15]\n",
            " Sanderson Brandon,  Sullivan Michael J. [Support=0.13]\n",
            " Gaiman Neil,  Sanderson Brandon [Support=0.15]\n",
            " Bancroft Josiah,  Brennan Marie [Support=0.12]\n",
            " Addison Katherine / Monette Sarah,  Bancroft Josiah [Support=0.14]\n",
            " Rowe Andrew,  Sanderson Brandon [Support=0.14]\n",
            " Sanderson Brandon,  VanderMeer Jeff [Support=0.11]\n",
            " Lawrence Mark,  Pratchett Terry [Support=0.11]\n",
            " Eames Nicholas,  Sanderson Brandon [Support=0.13]\n",
            " Mieville China,  Sanderson Brandon [Support=0.11]\n",
            " Abercrombie Joe,  Bancroft Josiah [Support=0.11]\n",
            " Jemisin N. K.,  Sanderson Brandon [Support=0.17]\n",
            " Bancroft Josiah,  Lynch Scott [Support=0.11]\n",
            " Jemisin N. K.,  Valente Catherynne M. [Support=0.12]\n",
            " Bancroft Josiah,  VanderMeer Jeff [Support=0.11]\n",
            " Bancroft Josiah,  Rowe Andrew [Support=0.12]\n",
            " Bancroft Josiah,  Gaiman Neil [Support=0.13]\n",
            " Bancroft Josiah,  Sullivan Michael J. [Support=0.14]\n",
            " Gaiman Neil,  Lawrence Mark [Support=0.12]\n",
            " Abercrombie Joe,  Sanderson Brandon [Support=0.11]\n",
            " Bancroft Josiah,  Lawrence Mark [Support=0.17]\n",
            " Hobb Robin / Lindholm Megan,  Jemisin N. K. [Support=0.12]\n",
            " Butcher Jim,  Sanderson Brandon [Support=0.11]\n",
            " Addison Katherine / Monette Sarah,  Sanderson Brandon [Support=0.14]\n",
            " Eames Nicholas,  Lawrence Mark [Support=0.12]\n",
            " Jemisin N. K.,  Novik Naomi [Support=0.12]\n",
            " Bancroft Josiah,  Hobb Robin / Lindholm Megan [Support=0.13]\n",
            " Bancroft Josiah,  Novik Naomi [Support=0.14]\n",
            " Brennan Marie,  Jemisin N. K. [Support=0.14]\n",
            " Lawrence Mark,  VanderMeer Jeff [Support=0.12]\n",
            " Arden Katherine,  Jemisin N. K. [Support=0.12]\n",
            " Hobb Robin / Lindholm Megan,  Lawrence Mark [Support=0.11]\n",
            " McClellan Brian,  Sanderson Brandon [Support=0.11]\n",
            " Bancroft Josiah,  Pratchett Terry [Support=0.16]\n",
            " Jemisin N. K.,  Le Guin Ursula K. [Support=0.11]\n"
          ]
        }
      ]
    }
  ]
}